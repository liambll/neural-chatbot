# -*- coding: utf-8 -*-

<<<<<<< HEAD
data_path = 'datasets/twitter/'
model_path = 'models/twitter/'
#data_path = 'datasets/cornell-movie/'
#model_path = 'models/cornell-movie/'
=======
#data_path = 'datasets/twitter/'
#model_path = 'models/twitter/'
data_path = 'datasets/cornell-movie/'
model_path = 'models/cornell-movie/'
>>>>>>> 6bbe915ae04da8e894df5665cfcc945353889629
vocab_size = 8000
source_len = 20
target_len = 20
layer_size = 512 #512
num_layers = 1  # 3
model_type = 1 #1 - Seq2Seq; 2 - Seq2Seq with attention # 3 - tied Seq2Seq
attention_heads = 1
reverseInput = False
batch_size = 64
learning_rate=0.001
epochs=30
<<<<<<< HEAD


=======
>>>>>>> 6bbe915ae04da8e894df5665cfcc945353889629
